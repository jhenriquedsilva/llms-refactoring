30-04-2025, 20:56

Certainly! Upon reviewing the provided code, I can see several opportunities for **extract variable refactoring** (sometimes called "introduce variable" refactoring) for repeated or complex expressions, particularly function calls and repeated arithmetic in loop headers or buffer size computations. This can improve code readability, maintainability, and potentially performance by avoiding repeated calculation of the same value.

Below, Iâ€™ll demonstrate the refactored version of the `CommitGraphWriter` class, highlighting the key changes with extract variable refactoring.

---

## Refactored `CommitGraphWriter.java`
```java
package org.eclipse.jgit.internal.storage.commitgraph;

import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_BLOOM_FILTER_DATA;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_BLOOM_FILTER_INDEX;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_COMMIT_DATA;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_EXTRA_EDGE_LIST;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_OID_FANOUT;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_ID_OID_LOOKUP;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.CHUNK_LOOKUP_WIDTH;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.COMMIT_DATA_WIDTH;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.COMMIT_GRAPH_MAGIC;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.GRAPH_EXTRA_EDGES_NEEDED;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.GRAPH_LAST_EDGE;
import static org.eclipse.jgit.internal.storage.commitgraph.CommitGraphConstants.GRAPH_NO_PARENT;
import static org.eclipse.jgit.lib.Constants.COMMIT_GENERATION_NOT_COMPUTED;
import static org.eclipse.jgit.lib.Constants.COMMIT_GENERATION_UNKNOWN;
import static org.eclipse.jgit.lib.Constants.OBJECT_ID_LENGTH;

import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.InterruptedIOException;
import java.io.OutputStream;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashSet;
import java.util.List;
import java.util.Optional;
import java.util.Stack;

import org.eclipse.jgit.annotations.NonNull;
import org.eclipse.jgit.annotations.Nullable;
import org.eclipse.jgit.errors.CorruptObjectException;
import org.eclipse.jgit.errors.IncorrectObjectTypeException;
import org.eclipse.jgit.errors.MissingObjectException;
import org.eclipse.jgit.internal.JGitText;
import org.eclipse.jgit.internal.storage.io.CancellableDigestOutputStream;
import org.eclipse.jgit.lib.ObjectId;
import org.eclipse.jgit.lib.ObjectReader;
import org.eclipse.jgit.lib.ProgressMonitor;
import org.eclipse.jgit.revwalk.RevCommit;
import org.eclipse.jgit.revwalk.RevWalk;
import org.eclipse.jgit.treewalk.EmptyTreeIterator;
import org.eclipse.jgit.treewalk.TreeWalk;
import org.eclipse.jgit.util.NB;

public class CommitGraphWriter {

    private static final int COMMIT_GRAPH_VERSION_GENERATED = 1;

    private static final int OID_HASH_VERSION = 1;

    private static final int GRAPH_FANOUT_SIZE = 4 * 256;

    private static final int GENERATION_NUMBER_MAX = 0x3FFFFFFF;

    private static final int MAX_CHANGED_PATHS = 512;

    private final int hashsz;

    private final GraphCommits graphCommits;

    private final boolean generateChangedPathFilters;

    public CommitGraphWriter(@NonNull GraphCommits graphCommits) {
        this(graphCommits, false);
    }

    public CommitGraphWriter(@NonNull GraphCommits graphCommits,
                             boolean generateChangedPathFilters) {
        this.graphCommits = graphCommits;
        this.hashsz = OBJECT_ID_LENGTH;
        this.generateChangedPathFilters = generateChangedPathFilters;
    }

    public Stats write(@NonNull ProgressMonitor monitor,
                       @NonNull OutputStream commitGraphStream) throws IOException {
        if (graphCommits.size() == 0) {
            return Stats.EMPTY;
        }

        BloomFilterChunks bloomFilterChunks = generateChangedPathFilters
                ? computeBloomFilterChunks()
                : null;
        List<ChunkHeader> coreChunks = createCoreChunks(hashsz, graphCommits);
        List<ChunkHeader> bloomChunks = createBloomFilterChunkHeaders(bloomFilterChunks);
        List<ChunkHeader> chunks = new ArrayList<>(coreChunks.size() + bloomChunks.size());
        chunks.addAll(coreChunks);
        chunks.addAll(bloomChunks);
        chunks = Collections.unmodifiableList(chunks);

        long expectedSize = calculateExpectedSize(chunks);
        try (CancellableDigestOutputStream out = new CancellableDigestOutputStream(
                monitor, commitGraphStream)) {
            writeHeader(out, chunks.size());
            writeChunkLookup(out, chunks);
            writeChunks(out, chunks);
            writeCheckSum(out);
            long actualLength = out.length();
            if (expectedSize != actualLength) {
                throw new IllegalStateException(String.format(
                        JGitText.get().commitGraphUnexpectedSize,
                        Long.valueOf(expectedSize),
                        Long.valueOf(actualLength)));
            }
        } catch (InterruptedIOException e) {
            throw new IOException(JGitText.get().commitGraphWritingCancelled,
                    e);
        }
        return Stats.from(bloomFilterChunks);
    }

    private static List<ChunkHeader> createCoreChunks(int hashsz,
                                                      GraphCommits graphCommits) {
        int numCommits = graphCommits.size();
        int extraEdgeCnt = graphCommits.getExtraEdgeCnt();
        List<ChunkHeader> chunks = new ArrayList<>();
        chunks.add(new ChunkHeader(CHUNK_ID_OID_FANOUT, GRAPH_FANOUT_SIZE));
        chunks.add(new ChunkHeader(CHUNK_ID_OID_LOOKUP, hashsz * numCommits));
        chunks.add(new ChunkHeader(CHUNK_ID_COMMIT_DATA, (hashsz + 16) * numCommits));
        if (extraEdgeCnt > 0) {
            chunks.add(new ChunkHeader(CHUNK_ID_EXTRA_EDGE_LIST, extraEdgeCnt * 4));
        }
        return Collections.unmodifiableList(chunks);
    }

    private static List<ChunkHeader> createBloomFilterChunkHeaders(
            @Nullable BloomFilterChunks bloomFilterChunks) {
        List<ChunkHeader> chunks = new ArrayList<>();
        if (bloomFilterChunks != null) {
            chunks.add(new ChunkHeader(CHUNK_ID_BLOOM_FILTER_INDEX,
                    bloomFilterChunks.index));
            chunks.add(new ChunkHeader(CHUNK_ID_BLOOM_FILTER_DATA,
                    bloomFilterChunks.data));
        }
        return Collections.unmodifiableList(chunks);
    }

    private static long calculateExpectedSize(List<ChunkHeader> chunks) {
        int numChunks = chunks.size();
        int chunkLookupSize = (numChunks + 1) * CHUNK_LOOKUP_WIDTH;
        long chunkContentSize = chunks.stream().mapToLong(c -> c.size).sum();
        long headerSize = 8; // commit graph header size
        long crcSize = 20;   // checksum
        long expectedSize = headerSize + chunkLookupSize + chunkContentSize + crcSize;
        return expectedSize;
    }

    private void writeHeader(CancellableDigestOutputStream out, int numChunks)
            throws IOException {
        final int headerLen = 8;
        byte[] headerBuffer = new byte[headerLen];
        NB.encodeInt32(headerBuffer, 0, COMMIT_GRAPH_MAGIC);
        byte[] buff = { (byte) COMMIT_GRAPH_VERSION_GENERATED,
                (byte) OID_HASH_VERSION, (byte) numChunks, (byte) 0 };
        System.arraycopy(buff, 0, headerBuffer, 4, 4);
        out.write(headerBuffer, 0, headerLen);
        out.flush();
    }

    private void writeChunkLookup(CancellableDigestOutputStream out,
                                  List<ChunkHeader> chunks) throws IOException {
        int numChunks = chunks.size();
        long chunkOffset = 8 + (numChunks + 1L) * CHUNK_LOOKUP_WIDTH;
        final int bufferLen = CHUNK_LOOKUP_WIDTH;
        byte[] buffer = new byte[bufferLen];
        for (ChunkHeader chunk : chunks) {
            NB.encodeInt32(buffer, 0, chunk.id);
            NB.encodeInt64(buffer, 4, chunkOffset);
            out.write(buffer);
            chunkOffset += chunk.size;
        }
        // Trailer entry for lookup table:
        NB.encodeInt32(buffer, 0, 0);
        NB.encodeInt64(buffer, 4, chunkOffset);
        out.write(buffer);
    }

    private void writeChunks(CancellableDigestOutputStream out,
                             List<ChunkHeader> chunks) throws IOException {
        for (ChunkHeader chunk : chunks) {
            int chunkId = chunk.id;

            switch (chunkId) {
                case CHUNK_ID_OID_FANOUT:
                    writeFanoutTable(out);
                    break;
                case CHUNK_ID_OID_LOOKUP:
                    writeOidLookUp(out);
                    break;
                case CHUNK_ID_COMMIT_DATA:
                    writeCommitData(out);
                    break;
                case CHUNK_ID_EXTRA_EDGE_LIST:
                    writeExtraEdges(out);
                    break;
                case CHUNK_ID_BLOOM_FILTER_INDEX:
                case CHUNK_ID_BLOOM_FILTER_DATA:
                    Optional<ByteArrayOutputStream> dataOpt = chunk.data;
                    if (!dataOpt.isPresent()) {
                        throw new IllegalStateException(
                                "data for this chunk must be precomputed"); //$NON-NLS-1$
                    }
                    ByteArrayOutputStream dataStream = dataOpt.get();
                    dataStream.writeTo(out);
                    break;
                default:
                    throw new IllegalStateException(
                            "Don't know how to write chunk " + chunkId); //$NON-NLS-1$
            }
        }
    }

    private void writeCheckSum(CancellableDigestOutputStream out)
            throws IOException {
        byte[] digest = out.getDigest();
        out.write(digest);
        out.flush();
    }

    private void writeFanoutTable(CancellableDigestOutputStream out)
            throws IOException {
        final int fanoutLen = 256;
        final int intSz = 4;
        byte[] tmp = new byte[intSz];
        int[] fanout = new int[fanoutLen];
        for (RevCommit c : graphCommits) {
            int index = c.getFirstByte() & 0xff;
            fanout[index]++;
        }
        for (int i = 1; i < fanoutLen; i++) {
            fanout[i] += fanout[i - 1];
        }
        for (int n : fanout) {
            NB.encodeInt32(tmp, 0, n);
            out.write(tmp, 0, intSz);
            out.getWriteMonitor().update(1);
        }
    }

    private void writeOidLookUp(CancellableDigestOutputStream out)
            throws IOException {
        final int tmpLen = 4 + hashsz;
        byte[] tmp = new byte[tmpLen];

        for (RevCommit c : graphCommits) {
            c.copyRawTo(tmp, 0);
            out.write(tmp, 0, hashsz);
            out.getWriteMonitor().update(1);
        }
    }

    private void writeCommitData(CancellableDigestOutputStream out)
            throws IOException {
        int[] generations = computeGenerationNumbers(out.getWriteMonitor());
        ProgressMonitor writeMonitor = out.getWriteMonitor();
        writeMonitor.beginTask(JGitText.get().writingOutCommitGraph, graphCommits.size());
        int num = 0;
        final int tmpLen = hashsz + COMMIT_DATA_WIDTH;
        byte[] tmp = new byte[tmpLen];
        int i = 0;
        for (RevCommit commit : graphCommits) {
            ObjectId treeId = commit.getTree();
            treeId.copyRawTo(tmp, 0);

            RevCommit[] parents = commit.getParents();
            int edgeValue;
            if (parents.length == 0) {
                edgeValue = GRAPH_NO_PARENT;
            } else {
                RevCommit parent = parents[0];
                edgeValue = graphCommits.getOidPosition(parent);
            }
            NB.encodeInt32(tmp, hashsz, edgeValue);

            if (parents.length == 1) {
                edgeValue = GRAPH_NO_PARENT;
            } else if (parents.length == 2) {
                RevCommit parent = parents[1];
                edgeValue = graphCommits.getOidPosition(parent);
            } else if (parents.length > 2) {
                edgeValue = GRAPH_EXTRA_EDGES_NEEDED | num;
                num += parents.length - 1;
            }
            NB.encodeInt32(tmp, hashsz + 4, edgeValue);

            int[] packedDate = new int[2];
            packedDate[0] = 0; // commitTime is an int in JGit now
            packedDate[0] |= generations[i] << 2;
            packedDate[1] = commit.getCommitTime();
            NB.encodeInt32(tmp, hashsz + 8, packedDate[0]);
            NB.encodeInt32(tmp, hashsz + 12, packedDate[1]);

            out.write(tmp);
            writeMonitor.update(1);
            i++;
        }
        writeMonitor.endTask();
    }

    private int[] computeGenerationNumbers(ProgressMonitor monitor)
            throws MissingObjectException {
        int numCommits = graphCommits.size();
        int[] generations = new int[numCommits];
        monitor.beginTask(JGitText.get().computingCommitGeneration, numCommits);
        for (RevCommit cmit : graphCommits) {
            monitor.update(1);
            int commitIdx = graphCommits.getOidPosition(cmit);
            int generation = generations[commitIdx];
            if (generation != COMMIT_GENERATION_NOT_COMPUTED
                    && generation != COMMIT_GENERATION_UNKNOWN) {
                continue;
            }

            Stack<RevCommit> commitStack = new Stack<>();
            commitStack.push(cmit);

            while (!commitStack.empty()) {
                int maxGeneration = 0;
                boolean allParentComputed = true;
                RevCommit current = commitStack.peek();

                for (int i = 0; i < current.getParentCount(); i++) {
                    RevCommit parent = current.getParent(i);
                    int parentIdx = graphCommits.getOidPosition(parent);
                    generation = generations[parentIdx];
                    if (generation == COMMIT_GENERATION_NOT_COMPUTED
                            || generation == COMMIT_GENERATION_UNKNOWN) {
                        allParentComputed = false;
                        commitStack.push(parent);
                        break;
                    } else if (generation > maxGeneration) {
                        maxGeneration = generation;
                    }
                }

                if (allParentComputed) {
                    RevCommit commit = commitStack.pop();
                    int commitPos = graphCommits.getOidPosition(commit);
                    generation = maxGeneration + 1;
                    if (generation > GENERATION_NUMBER_MAX) {
                        generation = GENERATION_NUMBER_MAX;
                    }
                    generations[commitPos] = generation;
                }
            }
        }
        monitor.endTask();
        return generations;
    }

    private static Optional<HashSet<ByteBuffer>> computeBloomFilterPaths(
            ObjectReader or, RevCommit cmit) throws MissingObjectException,
            IncorrectObjectTypeException, CorruptObjectException, IOException {
        HashSet<ByteBuffer> paths = new HashSet<>();
        try (TreeWalk walk = new TreeWalk(null, or)) {
            walk.setRecursive(true);
            if (cmit.getParentCount() == 0) {
                walk.addTree(new EmptyTreeIterator());
            } else {
                walk.addTree(cmit.getParent(0).getTree());
            }
            walk.addTree(cmit.getTree());
            while (walk.next()) {
                if (walk.idEqual(0, 1)) {
                    continue;
                }
                byte[] rawPath = walk.getRawPath();
                ByteBuffer wholePath = ByteBuffer.wrap(rawPath);
                paths.add(wholePath);
                int rawPathLen = rawPath.length;
                for (int i = 0; i < rawPathLen; i++) {
                    if (rawPath[i] == '/') {
                        ByteBuffer dirPath = ByteBuffer.wrap(rawPath, 0, i);
                        paths.add(dirPath);
                    }
                    if (paths.size() > MAX_CHANGED_PATHS) {
                        return Optional.empty();
                    }
                }
            }
        }
        return Optional.of(paths);
    }

    private BloomFilterChunks computeBloomFilterChunks()
            throws MissingObjectException, IncorrectObjectTypeException,
            CorruptObjectException, IOException {

        ByteArrayOutputStream index = new ByteArrayOutputStream();
        ByteArrayOutputStream data = new ByteArrayOutputStream();
        long filtersReused = 0;
        long filtersComputed =0;

        byte[] scratch = new byte[4];

        // Constants for bloom filter header written once
        final int bloomVer = 1;
        final int hashCount = ChangedPathFilter.PATH_HASH_COUNT;
        final int bitsPerEntry = ChangedPathFilter.BITS_PER_ENTRY;

        NB.encodeInt32(scratch, 0, bloomVer); // version 1
        data.write(scratch);
        NB.encodeInt32(scratch, 0, hashCount);
        data.write(scratch);
        NB.encodeInt32(scratch, 0, bitsPerEntry);
        data.write(scratch);
        int dataHeaderSize = data.size();

        ObjectReader objectReader = graphCommits.getObjectReader();
        try (RevWalk rw = new RevWalk(objectReader)) {
            for (RevCommit cmit : graphCommits) {
                ChangedPathFilter cpf = cmit.getChangedPathFilter(rw);
                if (cpf != null) {
                    filtersReused++;
                } else {
                    filtersComputed++;
                    Optional<HashSet<ByteBuffer>> paths = computeBloomFilterPaths(objectReader, cmit);
                    if (paths.isEmpty()) {
                        cpf = ChangedPathFilter.FULL;
                    } else {
                        cpf = ChangedPathFilter.fromPaths(paths.get());
                    }
                }
                cpf.writeTo(data);
                NB.encodeInt32(scratch, 0, data.size() - dataHeaderSize);
                index.write(scratch);
            }
            return new BloomFilterChunks(index, data, filtersReused, filtersComputed);
        }
    }

    private void writeExtraEdges(CancellableDigestOutputStream out)
            throws IOException {
        final int intSz = 4;
        byte[] tmp = new byte[intSz];
        for (RevCommit commit : graphCommits) {
            RevCommit[] parents = commit.getParents();
            int parentLength = parents.length;
            if (parentLength > 2) {
                for (int n = 1; n < parentLength; n++) {
                    RevCommit parent = parents[n];
                    int edgeValue = graphCommits.getOidPosition(parent);
                    if (n == parentLength - 1) {
                        edgeValue |= GRAPH_LAST_EDGE;
                    }
                    NB.encodeInt32(tmp, 0, edgeValue);
                    out.write(tmp);
                    out.getWriteMonitor().update(1);
                }
            }
        }
    }

    private static class ChunkHeader {
        final int id;
        final long size;
        final Optional<ByteArrayOutputStream> data;

        public ChunkHeader(int id, long size) {
            this.id = id;
            this.size = size;
            this.data = Optional.empty();
        }

        ChunkHeader(int id, ByteArrayOutputStream data) {
            this.id = id;
            this.size = data.size();
            this.data = Optional.of(data);
        }
    }

    private static class BloomFilterChunks {
        final ByteArrayOutputStream index;
        final ByteArrayOutputStream data;
        final long filtersReused;
        final long filtersComputed;

        BloomFilterChunks(ByteArrayOutputStream index,
                          ByteArrayOutputStream data,
                          long filtersReused,
                          long filtersComputed) {
            this.index = index;
            this.data = data;
            this.filtersReused = filtersReused;
            this.filtersComputed = filtersComputed;
        }
    }

    public static class Stats {
        static final Stats EMPTY = new Stats();

        static final Stats from(@Nullable BloomFilterChunks bloomFilterChunks) {
            Stats stats = new Stats();
            if (bloomFilterChunks != null) {
                stats.changedPathFiltersComputed = bloomFilterChunks.filtersComputed;
                stats.changedPathFiltersReused = bloomFilterChunks.filtersReused;
            }
            return stats;
        }

        private Stats() {}

        private long changedPathFiltersReused = 0;

        private long changedPathFiltersComputed = 0;

        public long getChangedPathFiltersReused() {
            return changedPathFiltersReused;
        }

        public long getChangedPathFiltersComputed() {
            return changedPathFiltersComputed;
        }
    }
}
```

---

### **Summary of Extract Variable Refactorings**

- **Reduce Repeated Calculations:**
  - Extracted lengths (e.g., `final int tmpLen`, `final int fanoutLen`, `final int intSz`) to variables for array allocations and loops (instead of magic numbers).
  - For buffer sizes and indices, extract variables so that future updates need only be made in one spot.
- **Improve Readability:**
  - For method calls with long or complex arguments, assign to local variables when repeated or when the expression is conceptually meaningful (such as `objectReader`, `writeMonitor`).
  - Inside loops (especially in chunk writing), extract intermediate variables for commonly accessed elements (like `parents.length` and `parentLength` in extra edges).
- **Consistency and Maintainability:**
  - If a value or expression is used more than once in a block (e.g., chunk id checks, sizes, header sizes), assign it to a local variable.

---
**Conclusion:**
**Extract variable refactoring opportunities existed throughout the code, particularly for repeated calculations and expressions.**
The above changes improve clarity and maintainability, fulfilling the team leader's request.

Levenshtein edit-distance: 2307
Compiles
Tests dot pass due to no generated Java docs