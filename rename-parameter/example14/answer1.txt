01-05-2025, 15:08

Below, I provide a review of **rename parameter refactoring opportunities** in the provided code, particularly focusing on identifiers that are parameters of methods or constructors. The aim is to improve clarity, readability, and consistency according to Java naming conventions.

### Key Refactoring Opportunities
Some parameter names are either too generic, misleading, or not self-explanatory. Examples include `terms`, `query`, `boost`, `m`, and others, which could be made more descriptive.

#### Suggested Improvements
Let's apply these guidelines:
- Be more explicit and consistent about what a parameter represents.
- Prefer plural for collections (lists/maps/sets).
- Use descriptive names even if they might seem verbose.

---

# **Refactored Class: `WeightedSpanTermExtractor`**
```java
package org.apache.lucene.search.highlight;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Set;
import org.apache.lucene.analysis.CachingTokenFilter;
import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.index.BinaryDocValues;
import org.apache.lucene.index.FieldInfos;
import org.apache.lucene.index.FilterLeafReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.LeafReader;
import org.apache.lucene.index.LeafReaderContext;
import org.apache.lucene.index.NumericDocValues;
import org.apache.lucene.index.SortedDocValues;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.memory.MemoryIndex;
import org.apache.lucene.queries.CommonTermsQuery;
import org.apache.lucene.queries.function.FunctionScoreQuery;
import org.apache.lucene.queries.spans.FieldMaskingSpanQuery;
import org.apache.lucene.queries.spans.SpanFirstQuery;
import org.apache.lucene.queries.spans.SpanNearQuery;
import org.apache.lucene.queries.spans.SpanNotQuery;
import org.apache.lucene.queries.spans.SpanOrQuery;
import org.apache.lucene.queries.spans.SpanQuery;
import org.apache.lucene.queries.spans.SpanTermQuery;
import org.apache.lucene.queries.spans.SpanWeight;
import org.apache.lucene.queries.spans.Spans;
import org.apache.lucene.search.BooleanClause;
import org.apache.lucene.search.BooleanQuery;
import org.apache.lucene.search.BoostQuery;
import org.apache.lucene.search.ConstantScoreQuery;
import org.apache.lucene.search.DisjunctionMaxQuery;
import org.apache.lucene.search.FieldExistsQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.MatchAllDocsQuery;
import org.apache.lucene.search.MultiPhraseQuery;
import org.apache.lucene.search.MultiTermQuery;
import org.apache.lucene.search.PhraseQuery;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.QueryVisitor;
import org.apache.lucene.search.ScoreMode;
import org.apache.lucene.search.SynonymQuery;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.util.Bits;
import org.apache.lucene.util.IOUtils;

public class WeightedSpanTermExtractor {

    private String fieldName;
    private TokenStream tokenStream;
    private final String defaultField;
    private boolean expandMultiTermQuery;
    private boolean cachedTokenStream;
    private boolean wrapToCaching = true;
    private int maxDocCharsToAnalyze;
    private boolean usePayloads = false;
    private LeafReader internalReader = null;

    public WeightedSpanTermExtractor() {
        this(null);
    }

    public WeightedSpanTermExtractor(String defaultField) {
        this.defaultField = defaultField;
    }

    /**
     * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied
     * <code>Query</code>.
     *
     * @param luceneQuery Query to extract Terms from
     * @param termWeightBoost Boost applied to the terms
     * @param weightedTermMap Map to place created WeightedSpanTerms in
     * @throws IOException If there is a low-level I/O error
     */
    protected void extract(Query luceneQuery, float termWeightBoost, Map<String, WeightedSpanTerm> weightedTermMap)
            throws IOException {
        if (luceneQuery instanceof BoostQuery) {
            BoostQuery boostQuery = (BoostQuery) luceneQuery;
            extract(boostQuery.getQuery(), termWeightBoost * boostQuery.getBoost(), weightedTermMap);
        } else if (luceneQuery instanceof BooleanQuery) {
            for (BooleanClause clause : (BooleanQuery) luceneQuery) {
                if (!clause.isProhibited()) {
                    extract(clause.getQuery(), termWeightBoost, weightedTermMap);
                }
            }
        } else if (luceneQuery instanceof PhraseQuery) {
            PhraseQuery phraseQuery = ((PhraseQuery) luceneQuery);
            Term[] phraseQueryTerms = phraseQuery.getTerms();
            if (phraseQueryTerms.length == 1) {
                extractWeightedSpanTerms(weightedTermMap, new SpanTermQuery(phraseQueryTerms[0]), termWeightBoost);
            } else {
                SpanQuery[] spanQueries = new SpanQuery[phraseQueryTerms.length];
                for (int i = 0; i < phraseQueryTerms.length; i++) {
                    spanQueries[i] = new SpanTermQuery(phraseQueryTerms[i]);
                }

                // sum position increments beyond 1
                int positionGaps = 0;
                int[] positions = phraseQuery.getPositions();
                if (positions.length >= 2) {
                    positionGaps =
                            Math.max(0, positions[positions.length - 1] - positions[0] - positions.length + 1);
                }

                boolean inOrder = (phraseQuery.getSlop() == 0);

                SpanNearQuery spanNearQuery =
                        new SpanNearQuery(spanQueries, phraseQuery.getSlop() + positionGaps, inOrder);
                extractWeightedSpanTerms(weightedTermMap, spanNearQuery, termWeightBoost);
            }
        } else if (luceneQuery instanceof TermQuery || luceneQuery instanceof SynonymQuery) {
            extractWeightedTerms(weightedTermMap, luceneQuery, termWeightBoost);
        } else if (luceneQuery instanceof SpanQuery) {
            extractWeightedSpanTerms(weightedTermMap, (SpanQuery) luceneQuery, termWeightBoost);
        } else if (luceneQuery instanceof ConstantScoreQuery) {
            final Query nestedQuery = ((ConstantScoreQuery) luceneQuery).getQuery();
            if (nestedQuery != null) {
                extract(nestedQuery, termWeightBoost, weightedTermMap);
            }
        } else if (luceneQuery instanceof CommonTermsQuery) {
            extractWeightedTerms(weightedTermMap, luceneQuery, termWeightBoost);
        } else if (luceneQuery instanceof DisjunctionMaxQuery) {
            for (Query clause : ((DisjunctionMaxQuery) luceneQuery)) {
                extract(clause, termWeightBoost, weightedTermMap);
            }
        } else if (luceneQuery instanceof MultiPhraseQuery) {
            final MultiPhraseQuery multiPhraseQuery = (MultiPhraseQuery) luceneQuery;
            final Term[][] termArrays = multiPhraseQuery.getTermArrays();
            final int[] positions = multiPhraseQuery.getPositions();
            if (positions.length > 0) {

                int maxPosition = positions[positions.length - 1];
                for (int i = 0; i < positions.length - 1; ++i) {
                    if (positions[i] > maxPosition) {
                        maxPosition = positions[i];
                    }
                }

                @SuppressWarnings({"unchecked", "rawtypes"})
                final List<SpanQuery>[] disjunctSpanQueryLists = new List[maxPosition + 1];
                int distinctPositions = 0;

                for (int i = 0; i < termArrays.length; ++i) {
                    final Term[] currentTermArray = termArrays[i];
                    List<SpanQuery> disjunctList = disjunctSpanQueryLists[positions[i]];
                    if (disjunctList == null) {
                        disjunctList = (disjunctSpanQueryLists[positions[i]] = new ArrayList<>(currentTermArray.length));
                        ++distinctPositions;
                    }
                    for (Term term : currentTermArray) {
                        disjunctList.add(new SpanTermQuery(term));
                    }
                }

                int positionGaps = 0;
                int position = 0;
                final SpanQuery[] spanClauses = new SpanQuery[distinctPositions];
                for (List<SpanQuery> disjunctList : disjunctSpanQueryLists) {
                    if (disjunctList != null) {
                        spanClauses[position++] = new SpanOrQuery(disjunctList.toArray(new SpanQuery[disjunctList.size()]));
                    } else {
                        ++positionGaps;
                    }
                }

                if (spanClauses.length == 1) {
                    extractWeightedSpanTerms(weightedTermMap, spanClauses[0], termWeightBoost);
                } else {
                    final int slop = multiPhraseQuery.getSlop();
                    final boolean inOrder = (slop == 0);

                    SpanNearQuery spanNearQuery = new SpanNearQuery(spanClauses, slop + positionGaps, inOrder);
                    extractWeightedSpanTerms(weightedTermMap, spanNearQuery, termWeightBoost);
                }
            }
        } else if (luceneQuery instanceof MatchAllDocsQuery) {
            // nothing
        } else if (luceneQuery instanceof FieldExistsQuery) {
            // nothing
        } else if (luceneQuery instanceof FunctionScoreQuery) {
            extract(((FunctionScoreQuery) luceneQuery).getWrappedQuery(), termWeightBoost, weightedTermMap);
        } else if (isQueryUnsupported(luceneQuery.getClass())) {
            // nothing
        } else {
            if (luceneQuery instanceof MultiTermQuery
                    && (!expandMultiTermQuery || !fieldNameComparator(((MultiTermQuery) luceneQuery).getField()))) {
                return;
            }
            final IndexReader indexReader = getLeafContext().reader();
            Query rewrittenQuery;
            if (luceneQuery instanceof MultiTermQuery) {
                rewrittenQuery =
                        MultiTermQuery.SCORING_BOOLEAN_REWRITE.rewrite(
                                new IndexSearcher(indexReader), (MultiTermQuery) luceneQuery);
            } else {
                rewrittenQuery = luceneQuery.rewrite(new IndexSearcher(indexReader));
            }
            if (rewrittenQuery != luceneQuery) {
                extract(rewrittenQuery, termWeightBoost, weightedTermMap);
            } else {
                extractUnknownQuery(luceneQuery, weightedTermMap);
            }
        }
    }

    protected boolean isQueryUnsupported(Class<? extends Query> queryClass) {
        if (queryClass.getName().startsWith("org.apache.lucene.spatial.")) {
            return true;
        }
        if (queryClass.getName().startsWith("org.apache.lucene.spatial3d.")) {
            return true;
        }
        return false;
    }

    protected void extractUnknownQuery(Query query, Map<String, WeightedSpanTerm> weightedTermMap)
            throws IOException {
        // for sub-classing to extract custom queries
    }

    /**
     * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied
     * <code>SpanQuery</code>.
     *
     * @param weightedTermMap Map to place created WeightedSpanTerms in
     * @param spanQuery SpanQuery to extract Terms from
     * @param termWeightBoost The boost for term weighting
     * @throws IOException If there is a low-level I/O error
     */
    protected void extractWeightedSpanTerms(
            Map<String, WeightedSpanTerm> weightedTermMap, SpanQuery spanQuery, float termWeightBoost) throws IOException {

        Set<String> spanQueryFieldNames = new HashSet<>();
        collectSpanQueryFields(spanQuery, spanQueryFieldNames);
        if (fieldName != null
                && spanQueryFieldNames.contains(fieldName) == false
                && (defaultField == null || spanQueryFieldNames.contains(defaultField) == false)) {
            return;
        }

        final boolean mustRewrite = mustRewriteQuery(spanQuery);
        final IndexSearcher searcher = new IndexSearcher(getLeafContext());
        searcher.setQueryCache(null);
        final SpanQuery rewrittenSpanQuery = mustRewrite ? (SpanQuery) searcher.rewrite(spanQuery) : spanQuery;

        final Set<Term> spanNonWeightedTerms = new HashSet<>();
        rewrittenSpanQuery.visit(QueryVisitor.termCollector(spanNonWeightedTerms));
        if (spanNonWeightedTerms.isEmpty()) {
            return;
        }

        final List<PositionSpan> spanPositions = new ArrayList<>();

        LeafReaderContext leafContext = getLeafContext();
        SpanWeight spanWeight =
                (SpanWeight)
                        searcher.createWeight(searcher.rewrite(rewrittenSpanQuery), ScoreMode.COMPLETE_NO_SCORES, 1);
        final Spans spans = spanWeight.getSpans(leafContext, SpanWeight.Postings.POSITIONS);
        if (spans == null) {
            return;
        }

        final Bits liveDocs = leafContext.reader().getLiveDocs();
        // collect span positions
        while (spans.nextDoc() != Spans.NO_MORE_DOCS) {
            if (liveDocs != null && liveDocs.get(spans.docID()) == false) {
                continue;
            }
            while (spans.nextStartPosition() != Spans.NO_MORE_POSITIONS) {
                spanPositions.add(new PositionSpan(spans.startPosition(), spans.endPosition() - 1));
            }
        }

        if (spanPositions.isEmpty()) {
            return;
        }

        for (final Term queryTerm : spanNonWeightedTerms) {
            if (fieldNameComparator(queryTerm.field())) {
                WeightedSpanTerm weightedSpanTerm = weightedTermMap.get(queryTerm.text());

                if (weightedSpanTerm == null) {
                    weightedSpanTerm = new WeightedSpanTerm(termWeightBoost, queryTerm.text());
                    weightedSpanTerm.addPositionSpans(spanPositions);
                    weightedSpanTerm.positionSensitive = true;
                    weightedTermMap.put(queryTerm.text(), weightedSpanTerm);
                } else {
                    if (spanPositions.size() > 0) {
                        weightedSpanTerm.addPositionSpans(spanPositions);
                    }
                }
            }
        }
    }

    /**
     * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied
     * <code>Query</code>.
     *
     * @param weightedTermMap Map to place created WeightedSpanTerms in
     * @param termCollectingQuery Query to extract Terms from
     * @param termWeightBoost The boost for term weighting
     * @throws IOException If there is a low-level I/O error
     */
    protected void extractWeightedTerms(Map<String, WeightedSpanTerm> weightedTermMap, Query termCollectingQuery, float termWeightBoost)
            throws IOException {
        Set<Term> foundTerms = new HashSet<>();
        final IndexSearcher searcher = new IndexSearcher(getLeafContext());
        searcher.rewrite(termCollectingQuery).visit(QueryVisitor.termCollector(foundTerms));

        for (final Term queryTerm : foundTerms) {
            if (fieldNameComparator(queryTerm.field())) {
                WeightedSpanTerm weightedSpanTerm = new WeightedSpanTerm(termWeightBoost, queryTerm.text());
                weightedTermMap.put(queryTerm.text(), weightedSpanTerm);
            }
        }
    }

    /** Necessary to implement matches for queries against <code>defaultField</code> */
    protected boolean fieldNameComparator(String fieldNameToCheck) {
        return fieldName == null
                || fieldName.equals(fieldNameToCheck)
                || (defaultField != null && defaultField.equals(fieldNameToCheck));
    }

    protected LeafReaderContext getLeafContext() throws IOException {
        if (internalReader == null) {
            boolean useCache = wrapToCaching && !(tokenStream instanceof CachingTokenFilter);

            // If it's from term vectors, simply wrap the underlying Terms in a reader
            if (tokenStream instanceof TokenStreamFromTermVector) {
                useCache = false;
                Terms termVectorTerms = ((TokenStreamFromTermVector) tokenStream).getTermVectorTerms();
                if (termVectorTerms.hasPositions() && termVectorTerms.hasOffsets()) {
                    internalReader =
                            new TermVectorLeafReader(DelegatingLeafReader.FIELD_NAME, termVectorTerms);
                }
            }

            // Use MemoryIndex (index/invert this tokenStream now)
            if (internalReader == null) {
                final MemoryIndex indexer = new MemoryIndex(true, usePayloads);
                if (useCache) {
                    assert !cachedTokenStream;
                    tokenStream =
                            new CachingTokenFilter(new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));
                    cachedTokenStream = true;
                    indexer.addField(DelegatingLeafReader.FIELD_NAME, tokenStream);
                } else {
                    indexer.addField(
                            DelegatingLeafReader.FIELD_NAME,
                            new OffsetLimitTokenFilter(tokenStream, maxDocCharsToAnalyze));
                }
                final IndexSearcher searcher = indexer.createSearcher();
                internalReader = ((LeafReaderContext) searcher.getTopReaderContext()).reader();
            }

            this.internalReader = new DelegatingLeafReader(internalReader);
        }

        return internalReader.getContext();
    }

    static final class DelegatingLeafReader extends FilterLeafReader {
        private static final String FIELD_NAME = "shadowed_field";

        DelegatingLeafReader(LeafReader in) {
            super(in);
        }

        @Override
        public FieldInfos getFieldInfos() {
            throw new UnsupportedOperationException();
        }

        @Override
        public Terms terms(String field) throws IOException {
            return super.terms(DelegatingLeafReader.FIELD_NAME);
        }

        @Override
        public NumericDocValues getNumericDocValues(String field) throws IOException {
            return super.getNumericDocValues(FIELD_NAME);
        }

        @Override
        public BinaryDocValues getBinaryDocValues(String field) throws IOException {
            return super.getBinaryDocValues(FIELD_NAME);
        }

        @Override
        public SortedDocValues getSortedDocValues(String field) throws IOException {
            return super.getSortedDocValues(FIELD_NAME);
        }

        @Override
        public NumericDocValues getNormValues(String field) throws IOException {
            return super.getNormValues(FIELD_NAME);
        }

        @Override
        public CacheHelper getCoreCacheHelper() {
            return null;
        }

        @Override
        public CacheHelper getReaderCacheHelper() {
            return null;
        }
    }

    /**
     * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>
     * TokenStream</code>.
     *
     * @param query that caused hit
     * @param boost boost for the terms
     * @param textTokenStream of text to be highlighted
     * @return Map containing WeightedSpanTerms
     * @throws IOException If there is a low-level I/O error
     */
    public Map<String, WeightedSpanTerm> getWeightedSpanTerms(
            Query query, float boost, TokenStream textTokenStream) throws IOException {
        return getWeightedSpanTerms(query, boost, textTokenStream, null);
    }

    /**
     * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>
     * TokenStream</code>.
     *
     * @param query that caused hit
     * @param boost boost for the terms
     * @param textTokenStream of text to be highlighted
     * @param restrictFieldName restricts Term's used based on field name
     * @return Map containing WeightedSpanTerms
     * @throws IOException If there is a low-level I/O error
     */
    public Map<String, WeightedSpanTerm> getWeightedSpanTerms(
            Query query, float boost, TokenStream textTokenStream, String restrictFieldName) throws IOException {
        this.fieldName = restrictFieldName;

        Map<String, WeightedSpanTerm> weightedSpanTermsMap = new PositionCheckingMap<>();
        this.tokenStream = textTokenStream;
        try {
            extract(query, boost, weightedSpanTermsMap);
        } finally {
            IOUtils.close(internalReader);
        }

        return weightedSpanTermsMap;
    }

    /**
     * Creates a Map of <code>WeightedSpanTerms</code> from the given <code>Query</code> and <code>
     * TokenStream</code>. Uses a supplied <code>IndexReader</code> to properly weight terms (for
     * gradient highlighting).
     *
     * @param query that caused hit
     * @param boost boost for the terms
     * @param textTokenStream of text to be highlighted
     * @param restrictFieldName restricts Term's used based on field name
     * @param indexReader to use for scoring
     * @return Map of WeightedSpanTerms with quasi tf/idf scores
     * @throws IOException If there is a low-level I/O error
     */
    public Map<String, WeightedSpanTerm> getWeightedSpanTermsWithScores(
            Query query, float boost, TokenStream textTokenStream, String restrictFieldName, IndexReader indexReader)
            throws IOException {
        this.fieldName = restrictFieldName;
        this.tokenStream = textTokenStream;

        Map<String, WeightedSpanTerm> weightedSpanTermsMap = new PositionCheckingMap<>();
        extract(query, boost, weightedSpanTermsMap);

        int totalNumDocs = indexReader.maxDoc();
        Set<String> weightedTermStrings = weightedSpanTermsMap.keySet();
        Iterator<String> keyIterator = weightedTermStrings.iterator();

        try {
            while (keyIterator.hasNext()) {
                WeightedSpanTerm weightedSpanTerm = weightedSpanTermsMap.get(keyIterator.next());
                int docFreq = indexReader.docFreq(new Term(restrictFieldName, weightedSpanTerm.term));
                float idf = (float) (Math.log(totalNumDocs / (double) (docFreq + 1)) + 1.0);
                weightedSpanTerm.weight *= idf;
            }
        } finally {
            IOUtils.close(internalReader);
        }

        return weightedSpanTermsMap;
    }

    protected void collectSpanQueryFields(SpanQuery spanQuery, Set<String> spanQueryFieldNames) {
        if (spanQuery instanceof FieldMaskingSpanQuery) {
            collectSpanQueryFields(((FieldMaskingSpanQuery) spanQuery).getMaskedQuery(), spanQueryFieldNames);
        } else if (spanQuery instanceof SpanFirstQuery) {
            collectSpanQueryFields(((SpanFirstQuery) spanQuery).getMatch(), spanQueryFieldNames);
        } else if (spanQuery instanceof SpanNearQuery) {
            for (final SpanQuery clause : ((SpanNearQuery) spanQuery).getClauses()) {
                collectSpanQueryFields(clause, spanQueryFieldNames);
            }
        } else if (spanQuery instanceof SpanNotQuery) {
            collectSpanQueryFields(((SpanNotQuery) spanQuery).getInclude(), spanQueryFieldNames);
        } else if (spanQuery instanceof SpanOrQuery) {
            for (final SpanQuery clause : ((SpanOrQuery) spanQuery).getClauses()) {
                collectSpanQueryFields(clause, spanQueryFieldNames);
            }
        } else {
            spanQueryFieldNames.add(spanQuery.getField());
        }
    }

    protected boolean mustRewriteQuery(SpanQuery spanQuery) {
        if (!expandMultiTermQuery) {
            return false;
        } else if (spanQuery instanceof FieldMaskingSpanQuery) {
            return mustRewriteQuery(((FieldMaskingSpanQuery) spanQuery).getMaskedQuery());
        } else if (spanQuery instanceof SpanFirstQuery) {
            return mustRewriteQuery(((SpanFirstQuery) spanQuery).getMatch());
        } else if (spanQuery instanceof SpanNearQuery) {
            for (final SpanQuery clause : ((SpanNearQuery) spanQuery).getClauses()) {
                if (mustRewriteQuery(clause)) {
                    return true;
                }
            }
            return false;
        } else if (spanQuery instanceof SpanNotQuery) {
            SpanNotQuery spanNotQuery = (SpanNotQuery) spanQuery;
            return mustRewriteQuery(spanNotQuery.getInclude())
                    || mustRewriteQuery(spanNotQuery.getExclude());
        } else if (spanQuery instanceof SpanOrQuery) {
            for (final SpanQuery clause : ((SpanOrQuery) spanQuery).getClauses()) {
                if (mustRewriteQuery(clause)) {
                    return true;
                }
            }
            return false;
        } else if (spanQuery instanceof SpanTermQuery) {
            return false;
        } else {
            return true;
        }
    }

    /**
     * This class makes sure that if both position sensitive and insensitive versions of the same term
     * are added, the position insensitive one wins.
     */
    protected static class PositionCheckingMap<K> extends HashMap<K, WeightedSpanTerm> {

        @Override
        public void putAll(Map<? extends K, ? extends WeightedSpanTerm> inputMap) {
            for (Map.Entry<? extends K, ? extends WeightedSpanTerm> entry : inputMap.entrySet())
                this.put(entry.getKey(), entry.getValue());
        }

        @Override
        public WeightedSpanTerm put(K key, WeightedSpanTerm value) {
            WeightedSpanTerm prevTerm = super.put(key, value);
            if (prevTerm != null && prevTerm.positionSensitive == false) {
                value.positionSensitive = false;
            }
            return prevTerm;
        }
    }

    public boolean getExpandMultiTermQuery() {
        return expandMultiTermQuery;
    }

    public void setExpandMultiTermQuery(boolean expandMultiTermQuery) {
        this.expandMultiTermQuery = expandMultiTermQuery;
    }

    public boolean isUsePayloads() {
        return usePayloads;
    }

    public void setUsePayloads(boolean usePayloads) {
        this.usePayloads = usePayloads;
    }

    public boolean isCachedTokenStream() {
        return cachedTokenStream;
    }

    public TokenStream getTokenStream() {
        assert tokenStream != null;
        return tokenStream;
    }

    public void setWrapIfNotCachingTokenFilter(boolean wrap) {
        this.wrapToCaching = wrap;
    }

    protected final void setMaxDocCharsToAnalyze(int maxDocCharsToAnalyze) {
        this.maxDocCharsToAnalyze = maxDocCharsToAnalyze;
    }
}
```

---

## **Summary of Changes**
- Renamed parameters for clarity and distinction (e.g., `query` → `luceneQuery` or `termCollectingQuery`, `terms` → `weightedTermMap`, `tokenStream` → `textTokenStream` where applicable, `boost` → `termWeightBoost`, etc.).
- Renamed loop/local variables to match improved parameter names, improving local flow readability.
- Updated javadocs to match improved parameter names.
- Renamed type parameter in `PositionCheckingMap` methods from `m` to `inputMap`.
- Many of these parameters are now much more self-descriptive, following standard Java conventions.

---

**If you want similar changes in non-parameter variable names or specific parts, let me know!**

Compiles